{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Docugenius","text":"<p>Docugenius is a tool that generates documentation for your python code using LLMs.  The library provides a simple CLI interface to generate documentation for your python code.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install docugenius\n</code></pre>"},{"location":"#quickstart","title":"Quickstart","text":"<p>Before running docugenius, make sure you exported your OpenAI API key as an environment variable.</p> <pre><code>export OPENAI_API_KEY=\"your-api-key\"\n</code></pre> <p>To generate documentation for your python code, run the following command:</p> <pre><code>docugenius path/to/python/code.py\n</code></pre> <p>The default model used is OpenAI <code>openai:gpt-4o</code>, but you can specify a different model using the <code>--model</code> flag.</p> <pre><code>docugenius path/to/python/code.py --model openai:gpt-4-mini\n</code></pre> <p>See the Supported Models section for a list of supported models. Supported Models</p> <p>If you want to run docugenius on an entire directory, you can pass the directory path as input.</p> <pre><code>docugenius path/to/python/directory\n</code></pre>"},{"location":"#cli-usage","title":"CLI Usage","text":"<pre><code>usage: docugenius [-h] [--model {openai:gpt-4o,openai:gpt-4o-mini}] [--docstring-format {google,numpy,sprinx}] [--skip-raises] [--skip-returns]\n                  [--skip-examples] [--output-path OUTPUT_PATH]\n                  input_path\n\npositional arguments:\n  input_path            The path to the input. You can also pass a directory to process all files in it.\n\noptions:\n  -h, --help            show this help message and exit\n  --model {openai:gpt-4o,openai:gpt-4o-mini}, -m {openai:gpt-4o,openai:gpt-4o-mini}\n                        The model to use for generating docstrings.\n  --docstring-format {google,numpy,sprinx}, -d {google,numpy,sprinx}\n                        The format of the generated docstrings.\n  --skip-raises, -r     Whether to include information about exceptions raised by the code.\n  --skip-returns, -R    Whether to include information about the return value of the code.\n  --skip-examples, -e   Whether to include examples of how to use the code.\n  --output-path OUTPUT_PATH, -o OUTPUT_PATH\n                        The path to the output file/destination. If not provided, the output will overwrite the input file. If a directory is passed as\n                        input, this should be a directory.\n</code></pre> <p>The output overwrites the input file. If you want to save the output to a different file, you can use the <code>--output-path</code> flag.</p> <pre><code>docugenius path/to/python/code.py --output path/to/output/file.py\n</code></pre>"},{"location":"extending-docugenius/","title":"Extending Docugenius","text":"<p>Docugenius is designed to be easily extensible, so you can add support for other models by subclassing the <code>Genius</code> class and implementing the necessary methods.</p>"},{"location":"extending-docugenius/#adding-support-for-other-models","title":"Adding Support for Other Models","text":"<p>To add support for other models, you need to subclass the <code>Genius</code> class and implement the needed methods, like below:</p> <pre><code>from docugenius.genius.genius import Genius\n\nclass YourCustomGenius(Genius):\n    def __init__(\n       self,\n        docstring_format: Literal[\"google\", \"numpy\", \"sprinx\"] = \"google\",\n        skip_raises: bool = False,\n        skip_returns: bool = False,\n        skip_examples: bool = False,\n        custom_param:int = 0,\n        **kwargs,\n    ):\n        super().__init__(docstring_format, skip_raises, skip_returns,skip_examples)\n        self.custom_param = custom_param\n\n\n    def _generate_docstring(self, code: str) -&gt; str:\n        # do something\n        output = ...\n        return output\n</code></pre> <p>And add your model to the supported models list and to the genius_factory function in <code>genius/__init__.py</code>.</p> <p>If you need to change the prompt and/or the cleaning fn please refer to the Genius class.</p>"},{"location":"supported-models/","title":"Supported Models","text":"<p>Currently, docugenius supports the following models:</p> <ul> <li><code>openai:gpt-4o</code></li> <li><code>openai:gpt-4-mini</code></li> </ul> <p>The library is designed to be easily extensible, so you can add support for other models by subclassing the <code>Genius</code> class and implementing the necessary methods.</p> <p>For more information on how to add support for other models, see the Extending Docugenius section.</p>"},{"location":"api-references/cli/","title":"CLI","text":""},{"location":"api-references/cli/#docugenius.cli.main","title":"<code>docugenius.cli.main</code>","text":""},{"location":"api-references/cli/#docugenius.cli.main.RunArgs","title":"<code>RunArgs</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A class to hold the arguments for running the docstring generation.</p> <p>Attributes:</p> Name Type Description <code>input_path</code> <code>str</code> <p>The path to the input file or directory.</p> <code>model</code> <code>str</code> <p>The model to use for generating docstrings.          Must be one of [\"openai:gpt-4o\", \"openai:gpt-4o-mini\"].</p> <code>docstring_format</code> <code>str</code> <p>The format of the generated docstrings.                     Must be one of [\"google\", \"numpy\", \"sprinx\"].</p> <code>skip_raises</code> <code>bool</code> <p>Whether to include information about exceptions raised by the code.</p> <code>skip_returns</code> <code>bool</code> <p>Whether to include information about the return value of the code.</p> <code>skip_examples</code> <code>bool</code> <p>Whether to include examples of how to use the code.</p> <code>output_path</code> <code>str</code> <p>The path to the output file/destination.                If not provided, the output will overwrite the input file.                If a directory is passed as input, this should be a directory.</p> <p>Raises:     ValueError: If the model or docstring_format is not one of the specified literals.</p>"},{"location":"api-references/cli/#docugenius.cli.main.RunArgs.is_recursive","title":"<code>is_recursive()</code>","text":"<p>Check if the input path is a directory or a file.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the input path is a directory, False if it is a file.</p> Source code in <code>docugenius/cli/main.py</code> <pre><code>def is_recursive(self) -&gt; bool:\n    \"\"\"\n    Check if the input path is a directory or a file.\n\n    Returns:\n        bool: True if the input path is a directory, False if it is a file.\n    \"\"\"\n    return Path(self.input_path).is_dir()\n</code></pre>"},{"location":"api-references/cli/#docugenius.cli.main.run","title":"<code>run(args)</code>","text":"<p>Run the docstring generation process based on the provided arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>RunArgs</code> <p>The arguments for running the docstring generation.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the input file/directory does not exist.</p> <code>Exception</code> <p>If there is an error during docstring generation.</p> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value.</p> Example <p>run(RunArgs(input_path='example.py', model='openai:gpt-4o'))</p> Source code in <code>docugenius/cli/main.py</code> <pre><code>def run(args: RunArgs):\n    \"\"\"\n    Run the docstring generation process based on the provided arguments.\n\n    Args:\n        args (RunArgs): The arguments for running the docstring generation.\n\n    Raises:\n        FileNotFoundError: If the input file/directory does not exist.\n        Exception: If there is an error during docstring generation.\n\n    Returns:\n        None: This function does not return a value.\n\n    Example:\n        &gt;&gt;&gt; run(RunArgs(input_path='example.py', model='openai:gpt-4o'))\n    \"\"\"\n\n    input_path = args.input_path\n    model = args.model\n    output_path = args.output_path\n\n    if args.is_recursive():\n        for file in find_python_files(input_path):\n            run_on_file(file, model, output_path)\n    else:\n        run_on_file(input_path, model, output_path)\n</code></pre>"},{"location":"api-references/cli/#docugenius.cli.main.run_on_file","title":"<code>run_on_file(input_file, model, output_file=None)</code>","text":"<p>Generate docstrings for the code in the specified input file.</p> <p>Parameters:</p> Name Type Description Default <code>input_file</code> <code>str</code> <p>The path to the input file.</p> required <code>model</code> <code>str</code> <p>The model to use for generating docstrings.</p> required <code>output_file</code> <code>str</code> <p>The path to the output file. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the input file does not exist.</p> <code>Exception</code> <p>If there is an error during docstring generation.</p> <p>Returns:</p> Name Type Description <code>None</code> <p>This function does not return a value.</p> Example <p>run_on_file('example.py', 'openai:gpt-4o')</p> Source code in <code>docugenius/cli/main.py</code> <pre><code>def run_on_file(input_file: str, model: str, output_file: str = None):\n    \"\"\"\n    Generate docstrings for the code in the specified input file.\n\n    Args:\n        input_file (str): The path to the input file.\n        model (str): The model to use for generating docstrings.\n        output_file (str, optional): The path to the output file. Defaults to None.\n\n    Raises:\n        FileNotFoundError: If the input file does not exist.\n        Exception: If there is an error during docstring generation.\n\n    Returns:\n        None: This function does not return a value.\n\n    Example:\n        &gt;&gt;&gt; run_on_file('example.py', 'openai:gpt-4o')\n    \"\"\"\n\n    with open(input_file) as f:\n        code = f.read()\n\n    genius = genius_factory(model)\n\n    docstring = genius.generate(code)\n\n    output_file = output_file or input_file\n\n    with open(output_file, \"w\") as f:\n        f.write(docstring)\n</code></pre>"},{"location":"api-references/genius/","title":"Genius","text":""},{"location":"api-references/genius/#docugenius.genius.genius","title":"<code>docugenius.genius.genius</code>","text":""},{"location":"api-references/genius/#docugenius.genius.genius.Genius","title":"<code>Genius(docstring_format='google', skip_raises=False, skip_returns=False, skip_examples=False, **kwargs)</code>","text":"<p>               Bases: <code>ABC</code></p> <p>An abstract class for generating docstrings for Python code.</p> <p>Parameters:</p> Name Type Description Default <code>docstring_format</code> <code>Literal['google', 'numpy', 'sprinx']</code> <p>The format of the docstring. Defaults to \"google\".</p> <code>'google'</code> <code>skip_raises</code> <code>bool</code> <p>Whether to include exceptions in the docstring. Defaults to False.</p> <code>False</code> <code>skip_returns</code> <code>bool</code> <p>Whether to include return values in the docstring. Defaults to False.</p> <code>False</code> <code>skip_examples</code> <code>bool</code> <p>Whether to include examples in the docstring. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided docstring_format is not valid.</p> Source code in <code>docugenius/genius/genius.py</code> <pre><code>def __init__(\n    self,\n    docstring_format: Literal[\"google\", \"numpy\", \"sprinx\"] = \"google\",\n    skip_raises: bool = False,\n    skip_returns: bool = False,\n    skip_examples: bool = False,\n    **kwargs,\n):\n    self.docstring_format = docstring_format\n    if docstring_format not in [\"google\", \"numpy\", \"sprinx\"]:\n        raise ValueError(\n            f\"Invalid docstring format {docstring_format}. Must be one of 'google', 'numpy', or 'sprinx'.\"\n        )\n    self.skip_raises = skip_raises\n    self.skip_returns = skip_returns\n    self.skip_examples = skip_examples\n    super().__init__()\n</code></pre>"},{"location":"api-references/genius/#docugenius.genius.genius.Genius.clean_llm_output","title":"<code>clean_llm_output(output)</code>","text":"<p>Clean the output from the LLM model by removing any leading or trailing whitespace.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>str</code> <p>The output from the LLM model.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The cleaned output.</p> Source code in <code>docugenius/genius/genius.py</code> <pre><code>def clean_llm_output(self, output: str) -&gt; str:\n    \"\"\"\n    Clean the output from the LLM model by removing any leading or trailing whitespace.\n\n    Parameters:\n        output (str): The output from the LLM model.\n\n    Returns:\n        str: The cleaned output.\n    \"\"\"\n    import re\n\n    output = re.findall(r\"```generated-python-code\\n(.*?)\\n```\", output, re.DOTALL)\n    if output:\n        output = output[0]\n    else:\n        output = \"\"\n\n    return output\n</code></pre>"},{"location":"api-references/genius/#docugenius.genius.genius.Genius.generate","title":"<code>generate(code)</code>","text":"<p>Generate a docstring for the given code.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>The code to generate a docstring for.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The code with the generated docstring added.</p> Source code in <code>docugenius/genius/genius.py</code> <pre><code>def generate(self, code: str) -&gt; str:\n    \"\"\"\n    Generate a docstring for the given code.\n\n    Parameters:\n        code (str): The code to generate a docstring for.\n\n    Returns:\n        str: The code with the generated docstring added.\n    \"\"\"\n    if not code or is_skippable(code):\n        return code\n\n    output = self._generate_docstring(code)\n    return self.clean_llm_output(output)\n</code></pre>"},{"location":"api-references/genius/#docugenius.genius.openai_genius","title":"<code>docugenius.genius.openai_genius</code>","text":""},{"location":"api-references/genius/#docugenius.genius.openai_genius.OpenAIGenius","title":"<code>OpenAIGenius(model, docstring_format='google', skip_raises=False, skip_returns=False, skip_examples=False)</code>","text":"<p>               Bases: <code>Genius</code></p> <p>A class to generate docstrings using OpenAI's API.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model to use for generating docstrings.</p> required <code>docstring_format</code> <code>Literal['google', 'numpy', 'sprinx']</code> <p>The format of the docstring. Defaults to \"google\".</p> <code>'google'</code> <code>skip_raises</code> <code>bool</code> <p>Whether to include exceptions in the docstring. Defaults to False.</p> <code>False</code> <code>skip_returns</code> <code>bool</code> <p>Whether to include return values in the docstring. Defaults to False.</p> <code>False</code> <code>skip_examples</code> <code>bool</code> <p>Whether to include examples in the docstring. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided model is not valid.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; genius = OpenAIGenius(model=\"gpt-4o-mini\")\n&gt;&gt;&gt; print(genius.docstring_format)\ngoogle\n</code></pre> <p>Initialize the OpenAIGenius instance.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model to use for generating docstrings.</p> required <code>docstring_format</code> <code>Literal['google', 'numpy', 'sprinx']</code> <p>The format of the docstring. Defaults to \"google\".</p> <code>'google'</code> <code>skip_raises</code> <code>bool</code> <p>Whether to include exceptions in the docstring. Defaults to False.</p> <code>False</code> <code>skip_returns</code> <code>bool</code> <p>Whether to include return values in the docstring. Defaults to False.</p> <code>False</code> <code>skip_examples</code> <code>bool</code> <p>Whether to include examples in the docstring. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided model is not valid.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; genius = OpenAIGenius(model=\"gpt-4o-mini\")\n</code></pre> Source code in <code>docugenius/genius/openai_genius.py</code> <pre><code>def __init__(\n    self,\n    model: str,\n    docstring_format: Literal[\"google\", \"numpy\", \"sprinx\"] = \"google\",\n    skip_raises: bool = False,\n    skip_returns: bool = False,\n    skip_examples: bool = False,\n):\n    \"\"\"\n    Initialize the OpenAIGenius instance.\n\n    Args:\n        model (str): The model to use for generating docstrings.\n        docstring_format (Literal[\"google\", \"numpy\", \"sprinx\"], optional): The format of the docstring. Defaults to \"google\".\n        skip_raises (bool, optional): Whether to include exceptions in the docstring. Defaults to False.\n        skip_returns (bool, optional): Whether to include return values in the docstring. Defaults to False.\n        skip_examples (bool, optional): Whether to include examples in the docstring. Defaults to False.\n\n    Raises:\n        ValueError: If the provided model is not valid.\n\n    Examples:\n        &gt;&gt;&gt; genius = OpenAIGenius(model=\"gpt-4o-mini\")\n    \"\"\"\n    import openai\n\n    super().__init__(docstring_format, skip_raises, skip_returns, skip_examples)\n    self._client = openai.OpenAI()\n    self.model = model\n</code></pre>"},{"location":"api-references/genius/#docugenius.genius.openai_genius.OpenAIGenius.clean_llm_output","title":"<code>clean_llm_output(output)</code>","text":"<p>Clean the output from the LLM model by removing any leading or trailing whitespace.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>str</code> <p>The output from the LLM model.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The cleaned output.</p> Source code in <code>docugenius/genius/genius.py</code> <pre><code>def clean_llm_output(self, output: str) -&gt; str:\n    \"\"\"\n    Clean the output from the LLM model by removing any leading or trailing whitespace.\n\n    Parameters:\n        output (str): The output from the LLM model.\n\n    Returns:\n        str: The cleaned output.\n    \"\"\"\n    import re\n\n    output = re.findall(r\"```generated-python-code\\n(.*?)\\n```\", output, re.DOTALL)\n    if output:\n        output = output[0]\n    else:\n        output = \"\"\n\n    return output\n</code></pre>"},{"location":"api-references/genius/#docugenius.genius.openai_genius.OpenAIGenius.generate","title":"<code>generate(code)</code>","text":"<p>Generate a docstring for the given code.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>The code to generate a docstring for.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The code with the generated docstring added.</p> Source code in <code>docugenius/genius/genius.py</code> <pre><code>def generate(self, code: str) -&gt; str:\n    \"\"\"\n    Generate a docstring for the given code.\n\n    Parameters:\n        code (str): The code to generate a docstring for.\n\n    Returns:\n        str: The code with the generated docstring added.\n    \"\"\"\n    if not code or is_skippable(code):\n        return code\n\n    output = self._generate_docstring(code)\n    return self.clean_llm_output(output)\n</code></pre>"}]}